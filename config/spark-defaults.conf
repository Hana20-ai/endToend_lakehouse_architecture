spark.master    yarn
spark.driver.memory     4g
spark.yarn.am.memory    2g
spark.executor.memory   4g
spark.executor.cores    2

#adding spark jars to hdfs 

#spark.yarn.jars=hdfs://hadoop-master:9000/user/spark/share/lib
spark.yarn.archive=hdfs://hadoop-master:9000/user/spark/share/lib



#download and include the Delta Lake package when starting a Spark session.12 scala version
spark.jars.packages io.delta:delta-core_2.12:2.2.0
spark.sql.extensions io.delta.sql.DeltaSparkSessionExtension
#use the DeltaCatalog as the catalog for storing metadata about your Delta Lake tables.
spark.sql.catalog.spark_catalog org.apache.spark.sql.delta.catalog.DeltaCatalog
#use the Hive metastore as the implementation for the Spark SQL catalog
#spark.sql.catalogImplementation=hive 